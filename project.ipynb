{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785fc004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import total_ordering, reduce\n",
    "import re\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from BTrees.OOBTree import OOBTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebc06975",
   "metadata": {},
   "outputs": [],
   "source": [
    "@total_ordering\n",
    "class Posting:\n",
    "\n",
    "    def __init__(self, doc_id: int):\n",
    "        self.doc_id = doc_id\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return other == self.doc_id\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        return self.doc_id > other\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self.doc_id)\n",
    "\n",
    "    def from_corpus(self, corpus):\n",
    "        return corpus[self.doc_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99126733",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostingsList:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._postings_list = []\n",
    "\n",
    "    @classmethod\n",
    "    def from_postings_list(cls, postings_list: list[Posting]) -> 'PostingsList':\n",
    "        plist = cls()\n",
    "        postings_list.sort()\n",
    "        plist._postings_list = postings_list\n",
    "        return plist\n",
    "\n",
    "    @classmethod\n",
    "    def from_doc_id(cls, doc_id: int):\n",
    "        plist = cls()\n",
    "        plist._postings_list = [Posting(doc_id)]\n",
    "        return plist\n",
    "\n",
    "    def merge(self, other: \"PostingsList\") -> 'PostingsList':\n",
    "        # A method to merge another PostingList into this one, avoiding duplicates.\n",
    "        i = 0  # Start index for the other PostingList.\n",
    "        last = self._postings_list[-1]  # The last Posting in the current list.\n",
    "        # Loop through the other PostingList and skip duplicates.\n",
    "        while (i < len(other._postings_list) and last == other._postings_list[i]):\n",
    "            i += 1  # Increment the index if a duplicate is found.\n",
    "        # Append the non-duplicate postings from the other list.\n",
    "        self._postings_list += other._postings_list[i:]\n",
    "        return self\n",
    "\n",
    "    def get_from_corpus(self, corpus):\n",
    "        return list(map(lambda x: x.from_corpus(corpus), self._postings_list))\n",
    "\n",
    "    def intersection(self, other: \"PostingsList\") -> 'PostingsList':\n",
    "        plist = []\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while (i < len(self._postings_list)) and (j < len(other._postings_list)):\n",
    "            if self._postings_list[i] == other._postings_list[j]:\n",
    "                plist.append(self._postings_list[i])\n",
    "                i += 1\n",
    "                j += 1\n",
    "            elif self._postings_list[i] <= other._postings_list[j]:\n",
    "                i += 1\n",
    "            else:\n",
    "                j += 1\n",
    "        return PostingsList.from_postings_list(plist)\n",
    "\n",
    "    def union(self, other: \"PostingsList\") -> 'PostingsList':\n",
    "        plist = []\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while (i < len(self._postings_list)) and (j < len(other._postings_list)):\n",
    "            if self._postings_list[i] == other._postings_list[j]:\n",
    "                plist.append(self._postings_list[i])\n",
    "                i += 1\n",
    "                j += 1\n",
    "            elif self._postings_list[i] < other._postings_list[j]:\n",
    "                plist.append(self._postings_list[i])\n",
    "                i += 1\n",
    "            else:\n",
    "                plist.append(other._postings_list[j])\n",
    "                j += 1\n",
    "        if i < len(self._postings_list):\n",
    "            plist += self._postings_list[i:]\n",
    "        elif j < len(other._postings_list):\n",
    "            plist += other._postings_list[j:]\n",
    "        return PostingsList.from_postings_list(plist)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \", \".join(map(str, self._postings_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6263f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImpossibleMergeException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "@total_ordering\n",
    "class Term:\n",
    "    def __init__(self, term: str, doc_id: int) -> None:\n",
    "        self.term = term\n",
    "        self.postings_list = PostingsList.from_doc_id(doc_id)\n",
    "\n",
    "    def merge(self, other: \"Term\") -> 'Term':\n",
    "        if self == other:\n",
    "            self.postings_list.merge(other.postings_list)\n",
    "        else:\n",
    "            raise ImpossibleMergeException\n",
    "        return self\n",
    "\n",
    "    def __eq__(self, other) -> bool:\n",
    "        return self.term == other.term\n",
    "\n",
    "    def __gt__(self, other) -> bool:\n",
    "        return self.term > other.term\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.term + \": \" + str(self.postings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c157c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.children = dict()\n",
    "        self.is_leaf = False\n",
    "        self.postings_list = None\n",
    "\n",
    "    def set_postings_list(self, postings_list: PostingsList) -> None:\n",
    "        self.postings_list = postings_list\n",
    "        self.is_leaf = True\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        to_return = \"\"\n",
    "        if self.is_leaf:\n",
    "            to_return += \": \" + str(self.postings_list) + \"\\n\"\n",
    "        for key in self.children:\n",
    "            to_return += str(key) + self.children[key].__repr__()\n",
    "        return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92ab3bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingKeyException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Trie:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.root = TrieNode()\n",
    "\n",
    "    def insert(self, node: Term) -> 'Trie':\n",
    "        current = self.root\n",
    "        for char in node.term:\n",
    "            if char not in current.children:\n",
    "                current.children[char] = TrieNode()\n",
    "            current = current.children[char]\n",
    "        if current.postings_list is not None:\n",
    "            current.postings_list.merge(node.postings_list)\n",
    "        else:\n",
    "            current.set_postings_list(node.postings_list)\n",
    "        return self\n",
    "\n",
    "    def search(self, key: str) -> PostingsList:\n",
    "        current = self.root\n",
    "        for char in key:\n",
    "            if char in current.children:\n",
    "                current = current.children[char]\n",
    "            else:\n",
    "                raise MissingKeyException\n",
    "        if current.postings_list is not None:\n",
    "            return current.postings_list\n",
    "        else:\n",
    "            raise MissingKeyException\n",
    "\n",
    "    def remove(self, key: str) -> None:\n",
    "        current = self.root\n",
    "        for char in key:\n",
    "            idx = ord(char) - ord('a')\n",
    "            child = current.children[idx]\n",
    "            if child is None:\n",
    "                raise MissingKeyException\n",
    "            else:\n",
    "                current = child\n",
    "        current = None\n",
    "\n",
    "    def merge(self, other: \"Trie\"):\n",
    "        stack = [(self.root, other.root)]\n",
    "        while stack:\n",
    "            node_self, node_other = stack.pop()\n",
    "            if node_other.postings_list is not None:\n",
    "                if node_self.postings_list is not None:\n",
    "                    node_self.postings_list.merge(node_other.postings_list)\n",
    "                else:\n",
    "                    node_self.set_postings_list(node_other.postings_list)\n",
    "            for key in node_other.children:\n",
    "                value = node_other.children[key]\n",
    "                if key not in node_self.children:\n",
    "                    node_self.children[key] = value\n",
    "                else:\n",
    "                    stack += [(node_self.children[key], value)]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.root.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "074b34d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    # Removes punctuation from the text using a regular expression.\n",
    "    no_punctuation = re.sub(r'[^\\w\\s^-]', '', text)\n",
    "    # Converts the text to lowercase.\n",
    "    downcase = no_punctuation.lower()\n",
    "    # Returns the normalized text.\n",
    "    return downcase\n",
    "\n",
    "\n",
    "def tokenize(content) -> list:\n",
    "    normalized = normalize(content)\n",
    "    return normalized.split()\n",
    "\n",
    "\n",
    "class InvertedIndex:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.btree = OOBTree()\n",
    "\n",
    "    @classmethod\n",
    "    def from_corpus(cls, corpus):\n",
    "        terms = {}\n",
    "        # per ogni documento\n",
    "        for doc_id, content in enumerate(tqdm(corpus)):\n",
    "            tokens = tokenize(content.description)\n",
    "            # per ogni parola\n",
    "            for token in tokens:\n",
    "                if token in terms:\n",
    "                    terms[token].merge(PostingsList.from_doc_id(doc_id))\n",
    "                else:\n",
    "                    terms[token] = PostingsList.from_doc_id(doc_id)\n",
    "\n",
    "                # mettilo nel trie\n",
    "        idx = cls()\n",
    "        idx.btree.update(terms)\n",
    "        return idx\n",
    "\n",
    "    def __getitem__(self, key: str) -> PostingsList:\n",
    "        # check if empty\n",
    "        return self.btree[key]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf68017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDescription:\n",
    "    def __init__(self, title: str, description: str):\n",
    "        self.title = title\n",
    "        self.description = description\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.title\n",
    "\n",
    "\n",
    "def read_movie_description(movie_metadata, description_file):\n",
    "    names = {}\n",
    "    corpus = []\n",
    "    with open(movie_metadata, 'r') as file:\n",
    "        movie_names = csv.reader(file, delimiter='\\t')\n",
    "        for description in movie_names:\n",
    "            names[description[0]] = description[2]\n",
    "    with open(description_file, 'r') as file:\n",
    "        descriptions = csv.reader(file, delimiter='\\t')\n",
    "        for description in descriptions:\n",
    "            try:\n",
    "                corpus.append(MovieDescription(\n",
    "                    names[description[0]], description[1]))\n",
    "            except KeyError:\n",
    "                pass\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9731a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrSystem:\n",
    "    def __init__(self, corpus: list[MovieDescription], index: InvertedIndex) -> None:\n",
    "        self._corpus = corpus\n",
    "        self._index = index\n",
    "\n",
    "    @classmethod\n",
    "    def from_corpus(cls, corpus: list[MovieDescription]) -> 'IrSystem':\n",
    "        index = InvertedIndex.from_corpus(corpus)\n",
    "        return cls(corpus, index)\n",
    "\n",
    "    def optimize_and_query(self, terms: list[str]):\n",
    "        plist = map(lambda x: self._index[x], terms)\n",
    "        plist = sorted(plist, key=lambda x: len(x))\n",
    "        result = reduce(lambda x, y: x.intersection(y), plist)\n",
    "        return result\n",
    "\n",
    "    def flatten_and_chains(self, query: str):\n",
    "        tokens = query.split()\n",
    "        postfix = infix_to_postfix(tokens)\n",
    "        stack = []\n",
    "        for token in postfix:\n",
    "            if token == 'AND':\n",
    "                left = stack.pop()\n",
    "                right = stack.pop()\n",
    "                if not isinstance(left, list):\n",
    "                    left = [left]\n",
    "                if not isinstance(right, list):\n",
    "                    right = [right]\n",
    "                stack.append(left + right)\n",
    "            elif token in ('OR', 'NOT'):\n",
    "                left = stack.pop()\n",
    "                right = stack.pop\n",
    "                if isinstance(left, list):\n",
    "                    left = self.optimize_and_query(left)\n",
    "                if isinstance(right, list):\n",
    "                    right = self.optimize_and_query(right)\n",
    "                if token == 'OR':\n",
    "                    stack.append(left.union(right))\n",
    "                else:\n",
    "                    stack.append(left.negation(right))\n",
    "            else:\n",
    "                stack.append(token)\n",
    "        result = stack.pop()\n",
    "        if isinstance(result, list):\n",
    "            result = self.optimize_and_query(result)\n",
    "        return result.get_from_corpus(self._corpus)\n",
    "\n",
    "\n",
    "def infix_to_postfix(tokens):\n",
    "    output = []\n",
    "    stack = []\n",
    "\n",
    "    for token in tokens:\n",
    "        token = token.upper()\n",
    "        if token in ('AND', 'OR', 'NOT'):\n",
    "            while (stack and stack[-1] != '('):\n",
    "                output.append(stack.pop())\n",
    "            stack.append(token)\n",
    "        elif token == '(':\n",
    "            stack.append(token)\n",
    "        elif token == ')':\n",
    "            while stack and stack[-1] != '(':\n",
    "                output.append(stack.pop())\n",
    "            stack.pop()  # remove '('\n",
    "        else:\n",
    "            output.append(token)\n",
    "\n",
    "    while stack:\n",
    "        output.append(stack.pop())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0659bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = read_movie_description(\n",
    "    '../Code IR/data/movie.metadata.tsv', '../Code IR/data/plot_summaries.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47838672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42204/42204 [00:26<00:00, 1621.25it/s]\n"
     ]
    }
   ],
   "source": [
    "ir = IrSystem.from_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "497473f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get_from_corpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_and_chains\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mluke\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 50\u001b[0m, in \u001b[0;36mIrSystem.flatten_and_chains\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     49\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize_and_query(result)\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_from_corpus\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_corpus)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get_from_corpus'"
     ]
    }
   ],
   "source": [
    "ir.flatten_and_chains('luke')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
